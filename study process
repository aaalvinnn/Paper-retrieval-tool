3.12
1、学习了网站爬取的基本知识，如通过网页检查或许所需对应信息的源代码标签，从而达到爬取的目的。爬取文章作者，序号，标题较为轻松，
但爬取日期时，因为文章日期在该页面没有显示，需要进入到论文的具体页面才能查看到，因此设计了一个子模块用于爬取文章的链接，再用
相同方法爬取某篇文章的日期（较为麻烦。后续思考如何优化）
2、爬取过程中也出现了一定的问题，如本次提交爬取页面时用的都是同一个用户头，疑似导致了被网站robot拦截的情况，从而爬取只能进行到
该页面的第14篇，下次提交将涉入随机虚拟用户头模块，以期解决
3.13
解决了第一项任务遗留的问题，目前基本完成了第一项任务所需要求（虽然代码并不是十分美观，并且索引的是2022的文章，最后更改下url即可）
1、准备第二项任务，在网上搜寻应该使用哪一种数据库。最初选择了简单轻量并封装在python的Sqlite,但后来发现sqlite是无服务器端的，运行于本地文件夹中的（虽然
也可以经过一定的处理手段间接连接服务端，但过于麻烦）于是选择了最常见的MySQL作为数据库。看到还要学习PHP语言和SQL语言，但找到了python的驱动（在安装mysql
时也可以安装python驱动包）
2、初步了解了一下flask框架，了解认识了为什么需要设计一个框架参与web应用开发（似乎发现了和数据库的联系？）。虽然在进行第二项任务时有点迷茫，目前大概找到
了方向
